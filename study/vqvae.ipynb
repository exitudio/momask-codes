{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~/backup_git\n",
    "~/git\n",
    "sudo tar -czvf /mnt/backup/epinyoan/git_no_momask.tar.gz --exclude=./momask-codes ./\n",
    "\n",
    "sudo tar -xvzf git_no_momask.tar.gz -C git_no_momask\n",
    "screen -r 59691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.chdir('../')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/epinyoan/miniconda3/envs/momask/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.vq.model import RVQVAE\n",
    "from models.vq.vq_trainer import RVQTokenizerTrainer\n",
    "from options.vq_option import arg_parse\n",
    "from data.t2m_dataset import MotionDataset\n",
    "from utils import paramUtil\n",
    "import numpy as np\n",
    "\n",
    "from models.t2m_eval_wrapper import EvaluatorModelWrapper\n",
    "from utils.get_opt import get_opt\n",
    "from motion_loaders.dataset_motion_loader import get_dataset_motion_loader\n",
    "\n",
    "from utils.motion_process import recover_from_ric\n",
    "from utils.plot_script import plot_3d_motion\n",
    "import datetime\n",
    "from data.t2m_dataset import Text2MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock:: opt\n"
     ]
    }
   ],
   "source": [
    "class Temp:\n",
    "    def __init__(self):\n",
    "        print('mock:: opt')\n",
    "opt = Temp()\n",
    "opt.data_root = './dataset/HumanML3D/'\n",
    "opt.motion_dir = pjoin(opt.data_root, 'new_joint_vecs')\n",
    "opt.text_dir = pjoin(opt.data_root, 'texts')\n",
    "opt.joints_num = 22\n",
    "opt.is_train = False # So it won't overwrite mean/std\n",
    "dim_pose = 263\n",
    "fps = 20\n",
    "radius = 4\n",
    "kinematic_chain = paramUtil.t2m_kinematic_chain\n",
    "dataset_opt_path = './checkpoints/t2m/Comp_v6_KLD005/opt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1460/1460 [00:00<00:00, 2510.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1300, snippets 116698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean = np.load('./dataset/HumanML3D/Mean.npy')\n",
    "std = np.load('./dataset/HumanML3D/Std.npy')\n",
    "### First stage\n",
    "opt.feat_bias = 5\n",
    "train_split_file = pjoin(opt.data_root, '/home/epinyoan/git/momask-codes/dataset/HumanML3D/val.txt')\n",
    "opt.window_size = 64\n",
    "opt.batch_size = 512\n",
    "train_dataset = MotionDataset(opt, mean, std, train_split_file)\n",
    "train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, num_workers=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.nb_code = 512 # doesn't matter\n",
    "opt.code_dim = 512\n",
    "opt.down_t = 2\n",
    "opt.stride_t = 2\n",
    "opt.width = 512\n",
    "opt.depth = 3\n",
    "opt.dilation_growth_rate = 3\n",
    "opt.vq_act = 'relu'\n",
    "opt.vq_norm = None\n",
    "\n",
    "opt.num_quantizers = 6\n",
    "opt.shared_codebook = False\n",
    "opt.quantize_dropout_prob = 0.2\n",
    "opt.mu = .99\n",
    "\n",
    "# dataset\n",
    "opt.dataset_name = 't2m'\n",
    "\n",
    "# vqdir = '/home/epinyoan/git/momask-codes/checkpoints/t2m/2023-12-21-16-46-46_lfq_cdim15_ent.1_div1_cmmt1_6e-5/'\n",
    "vqdir = '/home/epinyoan/git/momask-codes/log/vq/t2m/2024-01-08-13-41-16_momask_rerun_lr2e-4_bestFID'\n",
    "opt.meta_dir = vqdir+'/meta'\n",
    "net = RVQVAE(opt,\n",
    "            dim_pose,\n",
    "            opt.nb_code,\n",
    "            opt.code_dim,\n",
    "            opt.code_dim,\n",
    "            opt.down_t,\n",
    "            opt.stride_t,\n",
    "            opt.width,\n",
    "            opt.depth,\n",
    "            opt.dilation_growth_rate,\n",
    "            opt.vq_act,\n",
    "            opt.vq_norm)\n",
    "net.moment = {'mean': torch.from_numpy(train_loader.dataset.mean).cuda().float(), \n",
    "                'std': torch.from_numpy(train_loader.dataset.std).cuda().float()}\n",
    "\n",
    "\n",
    "# cb usage: 60309\n",
    "opt.resume_pth = vqdir+'/model/latest.tar'\n",
    "ckpt = torch.load(opt.resume_pth, map_location='cpu')\n",
    "net.load_state_dict(ckpt['vq_model'], strict=True)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_out: torch.Size([2, 512, 16])\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for i, batch in enumerate(train_loader):\n",
    "    motion = batch\n",
    "    # conds, motion, m_lens = batch\n",
    "    motion = motion.detach().float().cuda()\n",
    "    x_out, commit_loss, perplexity = net(motion[:2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebook Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second stage\n",
    "# opt.max_motion_length = 196\n",
    "# opt.batch_size = 64\n",
    "# train_split_file = pjoin(opt.data_root, '/home/epinyoan/git/momask-codes/dataset/HumanML3D/train.txt')\n",
    "# train_dataset = Text2MotionDataset(opt, mean, std, train_split_file)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, num_workers=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28521"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.unit_length = 4\n",
    "net.get_codebook_usage(train_loader, stage=1)\n",
    "# 25945  /32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = []\n",
    "for i, batch in enumerate(train_loader):\n",
    "    motion = batch\n",
    "    # conds, motion, m_lens = batch\n",
    "    motion = motion.detach().float().cuda()\n",
    "    code_idx, _ = net.encode(motion)\n",
    "    all_codes.append(code_idx.reshape(-1))\n",
    "all_codes = torch.cat(all_codes)\n",
    "u_codes, counts = all_codes.unique(return_counts=True)\n",
    "# u_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(105.4770, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sort(descending=True).values[:2**14].float().std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion_loaders.dataset_motion_loader import get_dataset_motion_loader\n",
    "from utils.eval_t2m import evaluation_vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./checkpoints/t2m/Comp_v6_KLD005/opt.txt\n",
      "Loading dataset t2m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [00:02<00:00, 2108.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n",
      "Ground Truth Dataset Loading Completed!!!\n"
     ]
    }
   ],
   "source": [
    "eval_val_loader, _ = get_dataset_motion_loader(dataset_opt_path, 32, 'test', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
